knitr::opts_chunk$set(echo = TRUE)
summary(house)
#ncol count -> col variable
col <- ncol(house)
house <- read.csv("./train.csv", stringsAsFactors = F)
library("tidyverse")
library("dplyr")
library("ggplot2")
library("httr")
library("readr")
library(rpart)
library(caret)
library(randomForest)
library(tree)
library(rpart.plot)
library(car)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
knitr::opts_chunk$set(echo = TRUE)
house <- read.csv("./train.csv", stringsAsFactors = F)
summary(house)
#ncol count -> col variable
col <- ncol(house)
#Print
cat("El número de columnas para el conjunto de datos es de :", col, "\n")
#nrow count -> row variable
row <- nrow(house)
#Print
cat("El número de observaciones para el conjunto de datos es de :", row)
top10 <- arrange(house, desc(house$SalePrice))
head (select(top10, "Neighborhood", "SalePrice"),30)
byneighborhood <- house %>% group_by(house$Neighborhood) %>% summarise(freq=n()) %>% ungroup()
byneighborhood <- arrange(byneighborhood, desc(byneighborhood$freq))
print(as_tibble(byneighborhood), n = 25)
yearly <- house %>% group_by(house$YrSold) %>% summarise(freq=n()) %>% ungroup()
yearly <- arrange(yearly, desc(yearly$freq))
print(as_tibble(yearly), n = 10)
conditions <- house %>% group_by(house$OverallCond) %>% summarise(freq=n()) %>% ungroup()
conditions <- arrange(conditions, desc(conditions$freq))
print(as_tibble(conditions), n = 10)
counts0 <- table(house$YrSold)
barplot(counts0, main="Sales Distribution",
xlab="Year of Sell")
counts <- table(house$YrSold, house$OverallCond)
barplot(counts, main="House Condition and Year of Sell",
xlab="House Condition", col=c("darkblue","red", "yellow", "cyan", "green"),
legend = rownames(counts), beside=TRUE)
scatterplot(house$SalePrice ~  house$OverallQual, data = house, smoother = FALSE, grid = FALSE, frame = FALSE)
quantile(house$SalePric)
scatterplot(house$SalePrice ~  house$OverallCond, data = house, smoother = FALSE, grid = FALSE, frame = FALSE)
clusterhouse <- fread("./train.csv", select = c("OverallQual","OverallCond" ,"GrLivArea", "BedroomAbvGr", "TotRmsAbvGrd", "GarageCars", "SalePrice", "YearBuilt", "LotArea", "LotFrontage"))
clusterhouse$LotFrontage[is.na(clusterhouse$LotFrontage)]<-0.0
set.seed(123)
clusterhouse<-clusterhouse[complete.cases("./train.csv")]
clusterhouse<-scale(clusterhouse)
hopkins(clusterhouse)
clusterhouse_dist <- dist(clusterhouse)
fviz_dist(clusterhouse_dist, show_labels = F)
fviz_nbclust(clusterhouse, kmeans, method = "wss") +
labs(subtitle = "Elbow method")
fviz_nbclust(clusterhouse, kmeans, method = "silhouette") +
labs(subtitle = "Silhouette method")
means <- kmeans(movies, 3, iter.max =100)
means <- kmeans(clusterhouse, 2, iter.max =100)
movies$means <- means$cluster
means <- kmeans(clusterhouse, 2, iter.max =100)
clusterhouse$means <- means$cluster
means <- kmeans(clusterhouse, 2, iter.max =100)
clusterhouse <- fread("./train.csv", select = c("OverallQual","OverallCond" ,"GrLivArea", "BedroomAbvGr", "TotRmsAbvGrd", "GarageCars", "SalePrice", "YearBuilt", "LotArea", "LotFrontage"))
clusterhouse$LotFrontage[is.na(clusterhouse$LotFrontage)]<-0.0
set.seed(123)
clusterhouse<-clusterhouse[complete.cases("./train.csv")]
clusterhouse<-scale(clusterhouse)
hopkins(clusterhouse)
means <- kmeans(clusterhouse, 2, iter.max =100)
clusterhouse$means <- means$cluster
km
means
means <- kmeans(clusterhouse, 2, iter.max =1000)
clusterhouse <- fread("./train.csv", select = c("OverallQual","OverallCond" ,"GrLivArea", "BedroomAbvGr", "TotRmsAbvGrd", "GarageCars", "SalePrice", "YearBuilt", "LotArea", "LotFrontage"))
clusterhouse$LotFrontage[is.na(clusterhouse$LotFrontage)]<-0.0
set.seed(123)
clusterhouse<-clusterhouse[complete.cases("./train.csv")]
clusterhouse<-scale(clusterhouse)
hopkins(clusterhouse)
means <- kmeans(clusterhouse, 2, iter.max =1000)
clusterhouse$means <- means$cluster
means
means$size
means <- kmeans(clusterhouse, 2, iter.max =1000)
clusterhouse <- fread("./train.csv", select = c("OverallQual","OverallCond" ,"GrLivArea", "BedroomAbvGr", "TotRmsAbvGrd", "GarageCars", "SalePrice", "YearBuilt", "LotArea", "LotFrontage"))
clusterhouse$LotFrontage[is.na(clusterhouse$LotFrontage)]<-0.0
set.seed(123)
clusterhouse<-clusterhouse[complete.cases("./train.csv")]
clusterhouse<-scale(clusterhouse)
hopkins(clusterhouse)
means <- kmeans(clusterhouse, 2, iter.max =1000)
clusterhouse$means <- means$cluster
means
means$size
means <- kmeans(clusterhouse_dist, 2, iter.max =1000)
clusterhouse$means <- means$cluster
means
means$size
means <- kmeans(clusterhouse_dist, 2, iter.max =1000)
clusterhouse$means <- means$cluster
means
clusterhouse <- fread("./train.csv", select = c("OverallQual","OverallCond" ,"GrLivArea", "BedroomAbvGr", "TotRmsAbvGrd", "SalePrice", "LotArea"))
clusterhouse$LotFrontage[is.na(clusterhouse$LotFrontage)]<-0.0
set.seed(123)
clusterhouse<-clusterhouse[complete.cases("./train.csv")]
clusterhouse<-scale(clusterhouse)
hopkins(clusterhouse)
clusterhouse_dist <- dist(clusterhouse)
fviz_dist(clusterhouse_dist, show_labels = F)
fviz_nbclust(clusterhouse, kmeans, method = "wss") +
labs(subtitle = "Elbow method")
means <- kmeans(clusterhouse, 2, iter.max =1000)
clusterhouse <- fread("./train.csv", select = c("OverallQual","OverallCond" ,"GrLivArea", "BedroomAbvGr", "TotRmsAbvGrd", "SalePrice", "LotArea"))
set.seed(123)
clusterhouse<-clusterhouse[complete.cases("./train.csv")]
clusterhouse<-scale(clusterhouse)
hopkins(clusterhouse)
clusterhouse_dist <- dist(clusterhouse)
fviz_dist(clusterhouse_dist, show_labels = F)
fviz_nbclust(clusterhouse, kmeans, method = "wss") +
labs(subtitle = "Elbow method")
fviz_nbclust(clusterhouse, kmeans, method = "silhouette") +
labs(subtitle = "Silhouette method")
means <- kmeans(clusterhouse, 2, iter.max =1000)
clusterhouse$means <- means$cluster
means
clusterhouse <- fread("./train.csv", select = c("OverallQual","OverallCond" ,  "TotRmsAbvGrd", "SalePrice", "LotArea"))
set.seed(123)
clusterhouse<-clusterhouse[complete.cases("./train.csv")]
clusterhouse<-scale(clusterhouse)
hopkins(clusterhouse)
clusterhouse_dist <- dist(clusterhouse)
fviz_dist(clusterhouse_dist, show_labels = F)
fviz_nbclust(clusterhouse, kmeans, method = "wss") +
labs(subtitle = "Elbow method")
fviz_nbclust(clusterhouse, kmeans, method = "silhouette") +
labs(subtitle = "Silhouette method")
means <- kmeans(clusterhouse, 2, iter.max =1000)
clusterhouse$means <- means$cluster
means
means$size
library(rpart)
library(caret)
library(tree)
library(rpart.plot)
library(randomForest)
datos <- iris
# variable respuesta la clase de la flor
porciento <- 70/100
set.seed(123)
trainRowsNumber<-sample(1:nrow(datos),porciento*nrow(datos))
train<-datos[trainRowsNumber,]
test<-datos[-trainRowsNumber,]
arbolModelo<-rpart(Species~.,datos,method = "class")
rpart.plot(arbolModelo)
save(train,test,arbolModelo, file = "Variables.RData")
load("Variables.RData")
dt_model<-rpart(Species~.,train,method = "class")
plot(dt_model);text(dt_model)
prp(dt_model)
rpart.plot(dt_model)
head(test)
prediccion <- predict(dt_model, newdata = test[1:4])
#Apply: Para cada fila, determina el nombre de la columna del valor mÃ¡ximo entre los tres valores de una fila
columnaMasAlta<-apply(prediccion, 1, function(x) colnames(prediccion)[which.max(x)])
test$prediccion<-columnaMasAlta #Se le aÃ±ade al grupo de prueba el valor de la predicciÃ³n
cfm<-confusionMatrix(as.factor(test$prediccion),test$Species)
cfm
#con caret
ct<-trainControl(method = "cv",train[,1:4],number=10, verboseIter=T)
modelorf<-train(Species~.,data=train,method="rpart",trControl = ct)
prediccionADVC<-predict(modelorf,newdata = test[,1:4])
test$predADVC<-prediccionADVC
cfmCaret <- confusionMatrix(test$predADVC,test$Species)
#con caret
ct<-trainControl(method = "cv",train[,1:4],number=10, verboseIter=T)
modelorf<-train(Species~.,data=train,method="rf",trControl = ct)
prediccionrfVC<-predict(modelorf,newdata = test[,1:4])
test$predrfVC<-prediccionrfVC
cfmCaret <- confusionMatrix(test$predrfVC,test$Species)
#con random forest
modeloRF1<-randomForest(Species~.,data=train)
prediccionRF1<-predict(modeloRF1,newdata = test[,1:4])
testCompleto<-test
testCompleto$predRF<-prediccionRF1
cfmRandomForest <- confusionMatrix(testCompleto$predRF, testCompleto$Species)
knitr::opts_chunk$set(echo = TRUE)
set.seed(123)
trainRowsNumber <- sample(1:nrow(house), 0.7*nrow(house))
train<-house[trainRowsNumber,]
test<-house[-trainRowsNumber,]
arbolModelo <- rpart(Species~.,house,method = "class")
library("tidyverse")
library("dplyr")
library("ggplot2")
library("httr")
library("readr")
library(rpart)
library(caret)
library(randomForest)
library(tree)
library(rpart.plot)
library(car)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
set.seed(123)
trainRowsNumber <- sample(1:nrow(house), 0.7*nrow(house))
train<-house[trainRowsNumber,]
test<-house[-trainRowsNumber,]
arbolModelo <- rpart(Species~.,house,method = "class")
house <- read.csv("./train.csv", stringsAsFactors = F)
set.seed(123)
trainRowsNumber <- sample(1:nrow(house), 0.7*nrow(house))
train<-house[trainRowsNumber,]
test<-house[-trainRowsNumber,]
arbolModelo <- rpart(Species~.,house,method = "class")
rpart
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
library("dplyr")
library("ggplot2")
library("httr")
library("readr")
library(rpart)
library(caret)
library(randomForest)
library(tree)
library(rpart.plot)
library(car)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
house <- read.csv("./train.csv", stringsAsFactors = F)
summary(house)
#ncol count -> col variable
col <- ncol(house)
#Print
cat("El número de columnas para el conjunto de datos es de :", col, "\n")
#nrow count -> row variable
row <- nrow(house)
#Print
cat("El número de observaciones para el conjunto de datos es de :", row)
top10 <- arrange(house, desc(house$SalePrice))
head (select(top10, "Neighborhood", "SalePrice"),30)
byneighborhood <- house %>% group_by(house$Neighborhood) %>% summarise(freq=n()) %>% ungroup()
byneighborhood <- arrange(byneighborhood, desc(byneighborhood$freq))
print(as_tibble(byneighborhood), n = 25)
yearly <- house %>% group_by(house$YrSold) %>% summarise(freq=n()) %>% ungroup()
yearly <- arrange(yearly, desc(yearly$freq))
print(as_tibble(yearly), n = 10)
conditions <- house %>% group_by(house$OverallCond) %>% summarise(freq=n()) %>% ungroup()
conditions <- arrange(conditions, desc(conditions$freq))
print(as_tibble(conditions), n = 10)
counts0 <- table(house$YrSold)
barplot(counts0, main="Sales Distribution",
xlab="Year of Sell")
counts <- table(house$YrSold, house$OverallCond)
barplot(counts, main="House Condition and Year of Sell",
xlab="House Condition", col=c("darkblue","red", "yellow", "cyan", "green"),
legend = rownames(counts), beside=TRUE)
scatterplot(house$SalePrice ~  house$OverallQual, data = house, smoother = FALSE, grid = FALSE, frame = FALSE)
scatterplot(house$SalePrice ~  house$OverallCond, data = house, smoother = FALSE, grid = FALSE, frame = FALSE)
quantile(house$SalePric)
clusterhouse <- fread("./train.csv", select = c("OverallQual","OverallCond" ,"GrLivArea", "BedroomAbvGr", "TotRmsAbvGrd", "GarageCars", "SalePrice", "YearBuilt", "LotArea", "LotFrontage"))
clusterhouse$LotFrontage[is.na(clusterhouse$LotFrontage)]<-0.0
set.seed(123)
clusterhouse<-clusterhouse[complete.cases("./train.csv")]
clusterhouse<-scale(clusterhouse)
hopkins(clusterhouse)
clusterhouse_dist <- dist(clusterhouse)
fviz_dist(clusterhouse_dist, show_labels = F)
fviz_nbclust(clusterhouse, kmeans, method = "wss") +
labs(subtitle = "Elbow method")
fviz_nbclust(clusterhouse, kmeans, method = "silhouette") +
labs(subtitle = "Silhouette method")
km<-kmeans(clusterhouse,2,iter.max =100)
clusterhouse$grupo<-km$cluster
km
km$size
hc<-hclust(clusterhouse_dist, method = "ward.D2")
plot(hc, cex=0.5, axes=FALSE) #Genera el dendograma
rect.hclust(hc,k=2)
set.seed(123)
trainRowsNumber <- sample(1:nrow(house), 0.7*nrow(house))
train<-house[trainRowsNumber,]
test<-house[-trainRowsNumber,]
arbolModelo <- rpart(Species~.,house,method = "class")
set.seed(123)
trainRowsNumber <- sample(1:nrow(house), 0.7*nrow(house))
train<-house[trainRowsNumber,]
test<-house[-trainRowsNumber,]
arbolModelo <- rpart(house,method = "class")
